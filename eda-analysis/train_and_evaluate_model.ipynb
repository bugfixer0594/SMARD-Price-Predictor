{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import Libraries\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from scipy.stats import mode\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load Processed Data\n",
    "\n",
    "# Get the directory of the current script\n",
    "SCRIPT_DIR = os.getcwd()\n",
    "\n",
    "DATA_DIR = os.path.join(SCRIPT_DIR, \"..\", \"data/finalized_files\")\n",
    "MODEL_DIR = os.path.join(SCRIPT_DIR, \"..\", \"models\")\n",
    "\n",
    "df_hourly = pd.read_csv(os.path.join(DATA_DIR, \"final_hourly_data.csv\"), sep=\",\", parse_dates=[\"Start date\"], low_memory=False)\n",
    "df_daily = pd.read_csv(os.path.join(DATA_DIR, \"final_daily_data.csv\"), sep=\",\", parse_dates=[\"Start date\"], low_memory=False)\n",
    "df_weekly = pd.read_csv(os.path.join(DATA_DIR, \"final_weekly_data.csv\"), sep=\",\", parse_dates=[\"Start date\"], low_memory=False)\n",
    "\n",
    "# Ensure proper datetime index\n",
    "df_hourly.set_index(\"Start date\", inplace=True)\n",
    "df_daily.set_index(\"Start date\", inplace=True)\n",
    "df_weekly.set_index(\"Start date\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Feature Engineering\n",
    "\n",
    "price_columns = [\n",
    "    \"Germany/Luxembourg [/MWh] Original resolutions\",\n",
    "    \"Belgium [/MWh] Original resolutions\",\n",
    "    \"France [/MWh] Original resolutions\"\n",
    "]\n",
    "\n",
    "df_hourly[\"Average_Price_‚Ç¨/MWh\"] = df_hourly[price_columns].mean(axis=1)\n",
    "df_daily[\"Average_Price_‚Ç¨/MWh\"] = df_daily[price_columns].mean(axis=1)\n",
    "df_weekly[\"Average_Price_‚Ç¨/MWh\"] = df_weekly[price_columns].mean(axis=1)\n",
    "\n",
    "# Ensure the column exists\n",
    "if \"Average_Price_‚Ç¨/MWh\" not in df_hourly.columns:\n",
    "    raise KeyError(\"‚ö† 'Average_Price_‚Ç¨/MWh' column not found in df_hourly!\")\n",
    "\n",
    "# Compute price direction labels (+1 = Up, -1 = Down, 0 = Stable)\n",
    "def compute_direction(price_series, threshold=0.1):\n",
    "    diff = price_series.diff()\n",
    "    return np.where(diff > threshold, 1, np.where(diff < -threshold, -1, 0))\n",
    "\n",
    "df_hourly[\"Price_Direction\"] = compute_direction(df_hourly[\"Average_Price_‚Ç¨/MWh\"]).astype(int)\n",
    "df_daily[\"Price_Direction\"] = compute_direction(df_daily[\"Average_Price_‚Ç¨/MWh\"]).astype(int)\n",
    "df_weekly[\"Price_Direction\"] = compute_direction(df_weekly[\"Average_Price_‚Ç¨/MWh\"]).astype(int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data preparation completed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elite\\AppData\\Local\\Temp\\ipykernel_30732\\2753602932.py:27: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df_hourly[\"Price_Change_1h\"] = df_hourly[\"Average_Price_‚Ç¨/MWh\"].pct_change(1) * 100\n",
      "C:\\Users\\Elite\\AppData\\Local\\Temp\\ipykernel_30732\\2753602932.py:28: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df_hourly[\"Price_Change_24h\"] = df_hourly[\"Average_Price_‚Ç¨/MWh\"].pct_change(24) * 100\n",
      "C:\\Users\\Elite\\AppData\\Local\\Temp\\ipykernel_30732\\2753602932.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.replace([np.inf, -np.inf], np.nan, inplace=True)  # Replace infinities\n",
      "C:\\Users\\Elite\\AppData\\Local\\Temp\\ipykernel_30732\\2753602932.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.fillna(0, inplace=True)  # Fill NaNs (use mean/median instead of 0 if needed)\n",
      "C:\\Users\\Elite\\AppData\\Local\\Temp\\ipykernel_30732\\2753602932.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.clip(-1e6, 1e6, inplace=True)  # Cap extreme values\n",
      "C:\\Users\\Elite\\AppData\\Local\\Temp\\ipykernel_30732\\2753602932.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.clip(-1e6, 1e6, inplace=True)  # Cap extreme values\n",
      "C:\\Users\\Elite\\AppData\\Local\\Temp\\ipykernel_30732\\2753602932.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.replace([np.inf, -np.inf], np.nan, inplace=True)  # Replace infinities\n",
      "C:\\Users\\Elite\\AppData\\Local\\Temp\\ipykernel_30732\\2753602932.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.fillna(0, inplace=True)  # Fill NaNs (use mean/median instead of 0 if needed)\n",
      "C:\\Users\\Elite\\AppData\\Local\\Temp\\ipykernel_30732\\2753602932.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.clip(-1e6, 1e6, inplace=True)  # Cap extreme values\n",
      "C:\\Users\\Elite\\AppData\\Local\\Temp\\ipykernel_30732\\2753602932.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.clip(-1e6, 1e6, inplace=True)  # Cap extreme values\n",
      "C:\\Users\\Elite\\AppData\\Local\\Temp\\ipykernel_30732\\2753602932.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.replace([np.inf, -np.inf], np.nan, inplace=True)  # Replace infinities\n",
      "C:\\Users\\Elite\\AppData\\Local\\Temp\\ipykernel_30732\\2753602932.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.fillna(0, inplace=True)  # Fill NaNs (use mean/median instead of 0 if needed)\n",
      "C:\\Users\\Elite\\AppData\\Local\\Temp\\ipykernel_30732\\2753602932.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.clip(-1e6, 1e6, inplace=True)  # Cap extreme values\n",
      "C:\\Users\\Elite\\AppData\\Local\\Temp\\ipykernel_30732\\2753602932.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.clip(-1e6, 1e6, inplace=True)  # Cap extreme values\n"
     ]
    }
   ],
   "source": [
    "# # Step 4: Prepare Data for Baseline & LSTM Models\n",
    "\n",
    "# Define target & label\n",
    "TARGET = \"Average_Price_‚Ç¨/MWh\"\n",
    "LABEL = \"Price_Direction\"\n",
    "\n",
    "# Ensure datetime index\n",
    "df_hourly = df_hourly.sort_index()\n",
    "df_daily = df_daily.sort_index()\n",
    "df_weekly = df_weekly.sort_index()\n",
    "\n",
    "# Rolling Mean Features\n",
    "df_hourly[\"Rolling_Mean_24h\"] = df_hourly[\"Average_Price_‚Ç¨/MWh\"].rolling(window=24).mean()\n",
    "df_daily[\"Rolling_Mean_7d\"] = df_daily[\"Average_Price_‚Ç¨/MWh\"].rolling(window=7).mean()\n",
    "\n",
    "# Price Differences\n",
    "df_hourly[\"Price_Diff\"] = df_hourly[\"Average_Price_‚Ç¨/MWh\"].diff()\n",
    "\n",
    "# Lag Features\n",
    "df_hourly[\"Lag_1h\"] = df_hourly[\"Average_Price_‚Ç¨/MWh\"].shift(1)\n",
    "df_hourly[\"Lag_24h\"] = df_hourly[\"Average_Price_‚Ç¨/MWh\"].shift(24)\n",
    "\n",
    "# Volatility (Rolling Standard Deviation)\n",
    "df_hourly[\"Volatility_24h\"] = df_hourly[\"Average_Price_‚Ç¨/MWh\"].rolling(window=24).std()\n",
    "\n",
    "# Percentage Change in Price\n",
    "df_hourly[\"Price_Change_1h\"] = df_hourly[\"Average_Price_‚Ç¨/MWh\"].pct_change(1) * 100\n",
    "df_hourly[\"Price_Change_24h\"] = df_hourly[\"Average_Price_‚Ç¨/MWh\"].pct_change(24) * 100\n",
    "\n",
    "# Fill NaN values after rolling/shift operations\n",
    "df_hourly.fillna(0, inplace=True)\n",
    "df_daily.fillna(0, inplace=True)\n",
    "df_weekly.fillna(0, inplace=True)\n",
    "\n",
    "# Expected feature sets per dataset\n",
    "expected_features_hourly = [\n",
    "    \"Rolling_Mean_24h\", \"Price_Diff\", \"Lag_1h\", \"Lag_24h\",\n",
    "    \"Volatility_24h\", \"Price_Change_1h\", \"Price_Change_24h\"\n",
    "]\n",
    "expected_features_daily = [\"Rolling_Mean_7d\"]\n",
    "\n",
    "# Ensure weekly features exist\n",
    "df_weekly[\"Rolling_Mean_4w\"] = df_weekly[\"Average_Price_‚Ç¨/MWh\"].rolling(window=4).mean()\n",
    "df_weekly.fillna(0, inplace=True)  # Fill NaNs after rolling\n",
    "expected_features_weekly = [\"Rolling_Mean_4w\"]\n",
    "\n",
    "# Feature selection\n",
    "X_hourly, y_hourly = df_hourly[expected_features_hourly], df_hourly[LABEL]\n",
    "X_daily, y_daily = df_daily[expected_features_daily], df_daily[LABEL]\n",
    "X_weekly, y_weekly = df_weekly[expected_features_weekly], df_weekly[LABEL]\n",
    "\n",
    "# Debugging: Check for issues in feature matrices\n",
    "for name, X in [(\"Hourly\", X_hourly), (\"Daily\", X_daily), (\"Weekly\", X_weekly)]:\n",
    "    if np.any(np.isnan(X)):\n",
    "        print(f\"‚ö† NaN values found in {name} dataset\")\n",
    "    if np.any(np.isinf(X)):\n",
    "        print(f\"‚ö† Infinite values found in {name} dataset\")\n",
    "    if np.any(X > 1e6):  # Adjust threshold if needed\n",
    "        print(f\"‚ö† Extremely large values detected in {name} dataset\")\n",
    "\n",
    "# Fix infinite values & extremely large numbers\n",
    "for X in [X_hourly, X_daily, X_weekly]:\n",
    "    X.replace([np.inf, -np.inf], np.nan, inplace=True)  # Replace infinities\n",
    "    X.fillna(0, inplace=True)  # Fill NaNs (use mean/median instead of 0 if needed)\n",
    "    X.clip(-1e6, 1e6, inplace=True)  # Cap extreme values\n",
    "\n",
    "# Normalize features for LSTM\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_hourly_scaled = scaler.fit_transform(X_hourly) if not X_hourly.empty else np.array([])\n",
    "X_daily_scaled = scaler.fit_transform(X_daily) if not X_daily.empty else np.array([])\n",
    "X_weekly_scaled = scaler.fit_transform(X_weekly) if not X_weekly.empty else np.array([])\n",
    "\n",
    "# Train-Test Split\n",
    "if X_hourly_scaled.size > 0:\n",
    "    X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(X_hourly_scaled, y_hourly, test_size=0.2, random_state=42)\n",
    "if X_daily_scaled.size > 0:\n",
    "    X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(X_daily_scaled, y_daily, test_size=0.2, random_state=42)\n",
    "if X_weekly_scaled.size > 0:\n",
    "    X_train_w, X_test_w, y_train_w, y_test_w = train_test_split(X_weekly_scaled, y_weekly, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape for LSTM (samples, time steps, features)\n",
    "if X_hourly_scaled.size > 0:\n",
    "    X_train_h_lstm = X_train_h.reshape((X_train_h.shape[0], 1, X_train_h.shape[1]))\n",
    "    X_test_h_lstm = X_test_h.reshape((X_test_h.shape[0], 1, X_test_h.shape[1]))\n",
    "\n",
    "if X_daily_scaled.size > 0:\n",
    "    X_train_d_lstm = X_train_d.reshape((X_train_d.shape[0], 1, X_train_d.shape[1]))\n",
    "    X_test_d_lstm = X_test_d.reshape((X_test_d.shape[0], 1, X_test_d.shape[1]))\n",
    "\n",
    "if X_weekly_scaled.size > 0:\n",
    "    X_train_w_lstm = X_train_w.reshape((X_train_w.shape[0], 1, X_train_w.shape[1]))\n",
    "    X_test_w_lstm = X_test_w.reshape((X_test_w.shape[0], 1, X_test_w.shape[1]))\n",
    "\n",
    "print(\"‚úÖ Data preparation completed successfully!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ† Fixed Feature Names: ['End_date', 'Germany/Luxembourg_/MWh_Original_resolutions', '_DE/LU_neighbours_/MWh_Original_resolutions', 'Belgium_/MWh_Original_resolutions', 'Denmark_1_/MWh_Original_resolutions', 'Denmark_2_/MWh_Original_resolutions', 'France_/MWh_Original_resolutions', 'Netherlands_/MWh_Original_resolutions', 'Norway_2_/MWh_Original_resolutions', 'Austria_/MWh_Original_resolutions']\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22505\n",
      "[LightGBM] [Info] Number of data points in the train set: 15244, number of used features: 91\n",
      "[LightGBM] [Info] Start training from score -2.349868\n",
      "[LightGBM] [Info] Start training from score -0.255663\n",
      "[LightGBM] [Info] Start training from score -2.038567\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "‚úÖ LightGBM Accuracy: 0.9973767051416579\n",
      "‚úÖ XGBoost Accuracy: 0.9958027282266527\n"
     ]
    }
   ],
   "source": [
    "# # # üõ† Step 5: Ensure `y_train_h` contains multiple classes\n",
    "\n",
    "# üõ† Step 1: Fix `Price_Direction` Computation\n",
    "def compute_direction(prices, threshold=0.05):\n",
    "    \"\"\"\n",
    "    Computes price direction based on percentage change.\n",
    "    Returns: 1 (rise), -1 (fall), 0 (stable)\n",
    "    \"\"\"\n",
    "    price_change = prices.pct_change().fillna(0)\n",
    "    direction = np.where(price_change > threshold, 1, np.where(price_change < -threshold, -1, 0))\n",
    "    return direction\n",
    "\n",
    "df_hourly[\"Price_Direction\"] = compute_direction(df_hourly[\"Average_Price_‚Ç¨/MWh\"], threshold=0.05)\n",
    "df_hourly[\"Price_Direction\"] = df_hourly[\"Price_Direction\"].fillna(0).astype(int)\n",
    "\n",
    "# Target variable\n",
    "y = df_hourly[\"Price_Direction\"]\n",
    "\n",
    "# Features (Drop unnecessary columns)\n",
    "X = df_hourly.drop(columns=[\"Timestamp\", \"Price_Direction\"], errors=\"ignore\")\n",
    "\n",
    "# üõ† Step 2: Handle NaN/Infinite Values in `X`\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)  # Replace infinities with NaN\n",
    "X.fillna(0, inplace=True)  # Fill NaNs with 0\n",
    "\n",
    "# üèó Step 3: Split Train/Test Data\n",
    "X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# üîÑ Adjust Labels to Start from 0\n",
    "y_train_h = y_train_h.replace({-1: 0, 0: 1, 1: 2})\n",
    "y_test_h = y_test_h.replace({-1: 0, 0: 1, 1: 2})\n",
    "\n",
    "# üõ† Step 4: Handle Class Imbalance (SMOTE)\n",
    "if len(np.unique(y_train_h)) == 1:\n",
    "    print(\"‚ö† Warning: Only one class detected! Applying SMOTE to balance classes.\")\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_h, y_train_h = smote.fit_resample(X_train_h, y_train_h)\n",
    "\n",
    "# print(\"Class distribution after SMOTE:\\n\", pd.Series(y_train_h).value_counts())\n",
    "\n",
    "# üõ† Step 5: Ensure Consistency Between Train & Test Features\n",
    "X_test_h = X_test_h[X_train_h.columns]  # Keep only features present in training\n",
    "\n",
    "# üèÜ Step 6: Train Baseline Models (LightGBM & XGBoost)\n",
    "lgb_model = lgb.LGBMClassifier()\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "# üöÄ Fix Feature Names by Removing Special Characters\n",
    "X_train_h.columns = [col.replace(\" \", \"_\").replace(\"{\", \"\").replace(\"}\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\":\", \"\").replace(\"\\\\\", \"\").replace(\"\\\"\", \"\") for col in X_train_h.columns]\n",
    "X_test_h.columns = X_train_h.columns  # Ensure test set has the same feature names\n",
    "\n",
    "# üîé Check the first few column names after fixing\n",
    "print(\"üõ† Fixed Feature Names:\", X_train_h.columns.tolist()[:10])\n",
    "\n",
    "lgb_model.fit(X_train_h, y_train_h)\n",
    "xgb_model.fit(X_train_h, y_train_h)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lgb = lgb_model.predict(X_test_h)\n",
    "y_pred_xgb = xgb_model.predict(X_test_h)\n",
    "\n",
    "# Evaluation\n",
    "print(\"‚úÖ LightGBM Accuracy:\", accuracy_score(y_test_h, y_pred_lgb))\n",
    "print(\"‚úÖ XGBoost Accuracy:\", accuracy_score(y_test_h, y_pred_xgb))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Accuracy: 0.8688352570828961\n",
      "üìà Actual Volatility: 0.6577\n",
      "üîÆ Predicted Volatility: 0.4124\n",
      "üìä Extreme Price Movement Accuracy: 0.9985\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Ensemble Predictions\n",
    "\n",
    "# Majority voting from LGBM, XGBoost, and LSTM\n",
    "ensemble_preds = np.round((y_pred_lgb + y_pred_xgb) / 3)\n",
    "\n",
    "# Final Accuracy\n",
    "print(\"Ensemble Model Accuracy:\", accuracy_score(y_test_h, ensemble_preds))\n",
    "\n",
    "# ‚ö†Ô∏è Volatility Capture \n",
    "actual_volatility = y_test_h.diff().std()\n",
    "predicted_volatility = pd.Series(ensemble_preds).diff().std()\n",
    "print(f\"üìà Actual Volatility: {actual_volatility:.4f}\")\n",
    "print(f\"üîÆ Predicted Volatility: {predicted_volatility:.4f}\")\n",
    "\n",
    "# ‚ö†Ô∏è Extreme Price Movement Detection\n",
    "y_test_h = pd.Series(y_test_h)\n",
    "extreme_moves = (y_test_h.abs() > 0.15).sum()\n",
    "extreme_correct = ((y_test_h.abs() > 0.15) & (np.abs(ensemble_preds) > 0.15)).sum()\n",
    "extreme_accuracy = extreme_correct / extreme_moves if extreme_moves > 0 else 0\n",
    "print(f\"üìä Extreme Price Movement Accuracy: {extreme_accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Directional Accuracy: 0.8688\n",
      "üìâ Mean Absolute Error (MAE): 0.1314\n",
      "üìä Root Mean Squared Error (RMSE): 0.3633\n",
      "üìä Volatility Capture Score: 0.6242\n",
      "‚ö†Ô∏è Extreme Price Movement Accuracy: 0.9985\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Evaluate the Model\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    # Convert to Pandas Series if needed\n",
    "    y_true = pd.Series(y_true)\n",
    "    y_pred = pd.Series(y_pred)\n",
    "\n",
    "    # ‚úÖ Directional Accuracy\n",
    "    directional_acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # üìâ Mean Absolute Error (MAE) & RMSE\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    # üìä Volatility Capture (Compare Standard Deviations)\n",
    "    true_volatility = np.std(y_true)\n",
    "    pred_volatility = np.std(y_pred)\n",
    "    volatility_capture = 1 - abs(true_volatility - pred_volatility) / true_volatility if true_volatility != 0 else 0\n",
    "\n",
    "    # ‚ö†Ô∏è Extreme Price Movement Accuracy\n",
    "    extreme_moves = (y_test_h.abs() > 0.15).sum()\n",
    "    extreme_correct = ((y_true.abs() > 0.15) & (np.abs(ensemble_preds) > 0.15)).sum()\n",
    "    extreme_accuracy = extreme_correct / extreme_moves if extreme_moves > 0 else 0\n",
    "\n",
    "    # üî• Print Evaluation Metrics\n",
    "    print(f\"‚úÖ Directional Accuracy: {directional_acc:.4f}\")\n",
    "    print(f\"üìâ Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "    print(f\"üìä Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "    print(f\"üìä Volatility Capture Score: {volatility_capture:.4f}\")\n",
    "    print(f\"‚ö†Ô∏è Extreme Price Movement Accuracy: {extreme_accuracy:.4f}\")\n",
    "\n",
    "# üîé Run Evaluation with New Metrics\n",
    "evaluate_model(y_test_h, ensemble_preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Models saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Save the Model\n",
    "\n",
    "# Save models\n",
    "joblib.dump(lgb_model, os.path.join(MODEL_DIR, \"lgb_market_model.pkl\"))\n",
    "joblib.dump(xgb_model, os.path.join(MODEL_DIR, \"xgb_market_model.pkl\"))\n",
    "\n",
    "print(\"‚úÖ Models saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
